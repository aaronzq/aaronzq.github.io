<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aaron&#39;s Blog</title>
    <link>https://aaronzq.github.io/</link>
    <description>Recent content on Aaron&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>aaron-zzz@outlook.com (Aaron)</managingEditor>
    <webMaster>aaron-zzz@outlook.com (Aaron)</webMaster>
    <copyright>(c) 2017 Aaron</copyright>
    <lastBuildDate>Fri, 29 Dec 2017 11:14:16 +0800</lastBuildDate>
    
	<atom:link href="https://aaronzq.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>BananaPiget</title>
      <link>https://aaronzq.github.io/2017/12/29/bananapiget/</link>
      <pubDate>Fri, 29 Dec 2017 11:14:16 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/12/29/bananapiget/</guid>
      <description>Take a Look This morning I get my BananaPi M3. I bought it for a consideration that it may replace RaspberryPi 3B in our application in embedded digital image processing. Quate from offical website:
&amp;gt; Banana Pi M3 is a super charged single board computer with an Octa-core processor and 2GB of RAM. Along side the elite processing unit, it features Gigabit Ethernet, 2 USB, SATA, WiFi, Bluetooth, and HDMI connection.</description>
    </item>
    
    <item>
      <title>Widefield vs. SPIM</title>
      <link>https://aaronzq.github.io/2017/12/17/widefield-vs.-spim/</link>
      <pubDate>Sun, 17 Dec 2017 19:48:46 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/12/17/widefield-vs.-spim/</guid>
      <description>SPIM: selective plane illumination microscope
If we use gaussian beam as illumination light, then the resolution of z axis is limited by the thickness of the beam in z direction. Note that the effective illumination region of the light is in the rayleigh distance, which by the way is proportional to the beam&amp;rsquo;s waist width^2, namely the thickness^2 of the beam as we mention above. So this distance decides the SPIM&amp;rsquo;s field of view.</description>
    </item>
    
    <item>
      <title>TransportVehicle</title>
      <link>https://aaronzq.github.io/2017/11/07/transportvehicle/</link>
      <pubDate>Tue, 07 Nov 2017 14:15:29 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/11/07/transportvehicle/</guid>
      <description>Outline Our robotcar First we can take a look at what we have made below out of the material around us. The main compents have been marked out as red text, they can be easily bought via internet and assembled by your home tool box. So finally we get this lovely cute robot car. Everything we design for it is included in my github.
There&amp;rsquo;s something I need to point out if someone thoroughly followed our PCB design.</description>
    </item>
    
    <item>
      <title>Labnote</title>
      <link>https://aaronzq.github.io/2017/10/24/labnote/</link>
      <pubDate>Tue, 24 Oct 2017 12:10:31 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/10/24/labnote/</guid>
      <description>10.24 The plan for this stage is to update the light field system to acquire a well-functioned 3D volume image compared to the former system.Since the MLA hasn&amp;rsquo;t arrived yet, what we could do is to validate the example based super resolution algorithm, expecially how well it works in the light field aspect.
Despite the adjustment of the parameters, namely patch size and neighbor number, it&amp;rsquo;s highly considerable how to set the patch database.</description>
    </item>
    
    <item>
      <title>List and Array operations in Python</title>
      <link>https://aaronzq.github.io/2017/10/23/list-and-array-operations-in-python/</link>
      <pubDate>Mon, 23 Oct 2017 17:00:15 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/10/23/list-and-array-operations-in-python/</guid>
      <description>todo a = list[range(0,10,1)] initial a list with range function, the 3rd para is the step
type(a) return the type of a, here it return &amp;lsquo;list&amp;rsquo;
b = len(a) return the length of list
a.append(11) insert an element into the rear of the list
pyplot manual
import numpy as np import matplotlib.pyplot as plt def f(t): return np.exp(-t) * np.cos(2*np.pi*t) t1 = np.arange(0.0, 5.0, 0.1) t2 = np.arange(0.0, 5.0, 0.</description>
    </item>
    
    <item>
      <title>Get Photo from Raspberry Pi</title>
      <link>https://aaronzq.github.io/2017/10/23/get-photo-from-raspberry-pi/</link>
      <pubDate>Mon, 23 Oct 2017 15:26:10 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/10/23/get-photo-from-raspberry-pi/</guid>
      <description>Get Image from Raspberry pi 1. Initialize the RaspberryPi with its camera Assuming that you have already configured your Raspberry Pi 3B+ and its camera module. We are going to use its internal camera package to simply grab the image and download to our PC.
2. Login on your Raspberry Pi with SSH and take shots For example, use putty.exe on Windows environment and login on to your Pi under the same network.</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://aaronzq.github.io/about/</link>
      <pubDate>Mon, 23 Oct 2017 15:25:13 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/about/</guid>
      <description> Education </description>
    </item>
    
    <item>
      <title>Build Python-Opencv Environment</title>
      <link>https://aaronzq.github.io/2017/10/22/build-python-opencv-environment/</link>
      <pubDate>Sun, 22 Oct 2017 15:26:10 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/10/22/build-python-opencv-environment/</guid>
      <description>On your Raspberry Pi  Check your cpu information: more /proc/cpuinfo
We may get the model name of the processor: ARMv7 Processor rev 4 (v7l)
 Check which version of Python your pip targets: pip -V
In default, pip will connect to python2.7 while pip3 connects to python3. If your pip is bound to python3 and you want to redirect it to python3. Try:  which pip  Locate the pip at /home/aaronrasp/.</description>
    </item>
    
    <item>
      <title>Adaptive Threshold</title>
      <link>https://aaronzq.github.io/2017/10/19/adaptive-threshold/</link>
      <pubDate>Thu, 19 Oct 2017 22:51:53 +0800</pubDate>
      <author>aaron-zzz@outlook.com (Aaron)</author>
      <guid>https://aaronzq.github.io/2017/10/19/adaptive-threshold/</guid>
      <description>AdaptiveThreshold Code: out=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,area,offset)  area(odd): in how big an area aroung a point it calculate the mean as a threshold
offset: the actual threshold is mean minus offset
Experiment: For a test, input the Shearing Interference Image(160*240),we manually set the threshold and estimate the best solution:
With adaptive threshold with different area varying in 91,71,51,31 and different offset in range of -10 to 9, we get the following result.</description>
    </item>
    
  </channel>
</rss>